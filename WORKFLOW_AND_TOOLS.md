## Workspace MCP: Workflows, Caching, and Tooling

This document explains, in depth, how the server discovers apps, builds metadata, generates and caches capsules, and serves fast hybrid search, along with a detailed reference for configuration and tools.

### High-Level Flow

```mermaid
graph TB
    FileSystem["ğŸ“ File System"]
    Scanner["ğŸ” Workspace Scanner"]
    Config["âš™ï¸ config.json"]
    Queue["ğŸ“‹ Job Queue"]
    Generator["ğŸ­ Capsule Generator"]
    Cache["ğŸ’¾ Capsule Cache"]
    Memory["ğŸ§  Capsule Memory"]
    Index["ğŸ“‡ Search Index"]
    Search["ğŸ” Hybrid Search"]
    Tools["ğŸ› ï¸ MCP Tools"]
    Client["ğŸ’» MCP Client"]

    FileSystem --> Scanner
    Config --> Scanner
    Scanner --> Queue
    Queue --> Generator
    Generator --> Cache
    Generator --> Memory
    Memory --> Index
    Index --> Search
    Search --> Tools
    Tools --> Client

    classDef scanner fill:#e1f5fe,stroke:#333,stroke-width:2px,color:#000
    classDef queue fill:#fff3e0,stroke:#333,stroke-width:2px,color:#000
    classDef generator fill:#f3e5f5,stroke:#333,stroke-width:2px,color:#000
    classDef storage fill:#f1f8e9,stroke:#333,stroke-width:2px,color:#000
    classDef search fill:#e3f2fd,stroke:#333,stroke-width:2px,color:#000
    classDef tools fill:#ede7f6,stroke:#333,stroke-width:2px,color:#000

    class Scanner scanner
    class Queue queue
    class Generator generator
    class Cache,Memory storage
    class Index,Search search
    class Tools tools
```

## ğŸ§  The Intelligence Behind Speed: How Capsules Transform AI Efficiency

### The Problem: Brute Force Workspace Scanning

Without MCP, AI services face this challenge every time:

```mermaid
flowchart TB
    subgraph Workspace ["ğŸ“ Raw Workspace (Thousands of Files)"]
        App1["ğŸ“ App 1<br/>â”œâ”€â”€ src/ (50 files)<br/>â”œâ”€â”€ tests/ (30 files)<br/>â”œâ”€â”€ docs/ (10 files)<br/>â””â”€â”€ â“ Purpose unknown"]
        App2["ğŸ“ App 2<br/>â”œâ”€â”€ components/ (200 files)<br/>â”œâ”€â”€ utils/ (40 files)<br/>â”œâ”€â”€ styles/ (60 files)<br/>â””â”€â”€ â“ Purpose unknown"]
        App3["ğŸ“ App 3<br/>â”œâ”€â”€ modules/ (80 files)<br/>â”œâ”€â”€ config/ (15 files)<br/>â”œâ”€â”€ scripts/ (25 files)<br/>â””â”€â”€ â“ Purpose unknown"]
        AppN["ğŸ“ ... App N<br/>â”œâ”€â”€ â“ Unknown structure<br/>â””â”€â”€ â“ Unknown purpose"]
    end
    
    AI["ğŸ¤– AI Service"] --> Scan1["ğŸ” Scan App 1<br/>â±ï¸ Read 90 files<br/>ğŸ§  Analyze purpose<br/>ğŸ“ Understand structure"]
    AI --> Scan2["ğŸ” Scan App 2<br/>â±ï¸ Read 300 files<br/>ğŸ§  Analyze purpose<br/>ğŸ“ Understand structure"]
    AI --> Scan3["ğŸ” Scan App 3<br/>â±ï¸ Read 120 files<br/>ğŸ§  Analyze purpose<br/>ğŸ“ Understand structure"]
    AI --> ScanN["ğŸ” Scan App N<br/>â±ï¸ Read ??? files<br/>ğŸ§  Analyze purpose<br/>ğŸ“ Understand structure"]
    
    Scan1 --> Slow["ğŸŒ SLOW RESULT<br/>â±ï¸ Minutes per query<br/>ğŸ’¸ High compute cost<br/>ğŸ”„ Repeated work"]
    Scan2 --> Slow
    Scan3 --> Slow
    ScanN --> Slow

    classDef workspace fill:#ffebee,stroke:#d32f2f,stroke-width:2px,color:#000
    classDef ai fill:#e3f2fd,stroke:#333,stroke-width:2px,color:#000
    classDef scan fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef slow fill:#ffcdd2,stroke:#d32f2f,stroke-width:3px,color:#000

    class App1,App2,App3,AppN workspace
    class AI ai
    class Scan1,Scan2,Scan3,ScanN scan
    class Slow slow
```

### The Solution: Intelligent Capsule-Based Navigation

With MCP, AI services get a **pre-computed intelligence layer**:

```mermaid
flowchart TB
    subgraph MCP ["ğŸ§  MCP Intelligence Layer"]
        direction TB
        
        subgraph Capsules ["ğŸ“¦ Smart Capsules (Pre-computed)"]
            Cap1["ğŸ“¦ App 1 Capsule<br/>ğŸ¯ Purpose: 'User authentication service'<br/>ğŸšª Entry: auth/main.py<br/>ğŸ§ª Tests: tests/auth/<br/>ğŸ“š Docs: docs/auth.md<br/>âš¡ Ready to query"]
            
            Cap2["ğŸ“¦ App 2 Capsule<br/>ğŸ¯ Purpose: 'React UI components library'<br/>ğŸšª Entry: src/index.tsx<br/>ğŸ§ª Tests: __tests__/<br/>ğŸ“š Docs: README.md<br/>âš¡ Ready to query"]
            
            Cap3["ğŸ“¦ App 3 Capsule<br/>ğŸ¯ Purpose: 'Payment processing API'<br/>ğŸšª Entry: server/app.js<br/>ğŸ§ª Tests: tests/integration/<br/>ğŸ“š Docs: docs/api.md<br/>âš¡ Ready to query"]
        end
        
        subgraph Indexes ["ğŸ“‡ Search Indexes (Pre-built)"]
            Idx1["ğŸ“‡ App 1 Index<br/>ğŸ” BM25 + Semantic<br/>ğŸ“Š Ranked relevance<br/>âš¡ Instant lookup"]
            Idx2["ğŸ“‡ App 2 Index<br/>ğŸ” BM25 + Semantic<br/>ğŸ“Š Ranked relevance<br/>âš¡ Instant lookup"]
            Idx3["ğŸ“‡ App 3 Index<br/>ğŸ” BM25 + Semantic<br/>ğŸ“Š Ranked relevance<br/>âš¡ Instant lookup"]
        end
    end
    
    AI["ğŸ¤– AI Service"] --> Smart["ğŸ§  Smart Query:<br/>'Where is user authentication?'"]
    Smart --> Cap1
    Cap1 --> Target["ğŸ¯ Direct to: auth/main.py<br/>âš¡ Instant result<br/>ğŸ“Š High confidence<br/>ğŸ¯ Precise targeting"]
    
    AI2["ğŸ¤– AI Service"] --> Smart2["ğŸ§  Smart Query:<br/>'How does payment work?'"]
    Smart2 --> Cap3
    Cap3 --> Target2["ğŸ¯ Direct to: server/app.js<br/>âš¡ Instant result<br/>ğŸ“Š High confidence<br/>ğŸ¯ Precise targeting"]

    classDef capsule fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000
    classDef index fill:#e3f2fd,stroke:#2196f3,stroke-width:2px,color:#000
    classDef ai fill:#fff3e0,stroke:#333,stroke-width:2px,color:#000
    classDef smart fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px,color:#000
    classDef target fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000

    class Cap1,Cap2,Cap3 capsule
    class Idx1,Idx2,Idx3 index
    class AI,AI2 ai
    class Smart,Smart2 smart
    class Target,Target2 target
```

**Key Insight**: Instead of scanning thousands of files every time, the AI service navigates through **intelligent capsules** that already know each app's purpose, structure, and key files.

## ğŸ—‚ï¸ Hierarchical Navigation: From Concept to File

### How AI Services Navigate the Workspace Hierarchy

```mermaid
flowchart LR
    subgraph Query ["ğŸ” AI Query Process"]
        Q["ğŸ¤– AI Query:<br/>'Where is authentication handled?'"]
    end
    
    subgraph Level1 ["ğŸŒŸ Level 1: Capsule Discovery"]
        C1["ğŸ“¦ Auth Service<br/>ğŸ¯ Purpose: 'User authentication'<br/>â­ Relevance: 95%"]
        C2["ğŸ“¦ UI Components<br/>ğŸ¯ Purpose: 'React components'<br/>â­ Relevance: 15%"]
        C3["ğŸ“¦ Payment API<br/>ğŸ¯ Purpose: 'Payment processing'<br/>â­ Relevance: 5%"]
    end
    
    subgraph Level2 ["ğŸ“‚ Level 2: Structure Navigation"]
        S1["ğŸšª Entrypoints:<br/>â€¢ auth/main.py<br/>â€¢ auth/middleware.py"]
        S2["ğŸ§ª Tests:<br/>â€¢ tests/auth/test_login.py<br/>â€¢ tests/auth/test_tokens.py"]
        S3["ğŸ“š Docs:<br/>â€¢ docs/authentication.md<br/>â€¢ README.md"]
    end
    
    subgraph Level3 ["ğŸ“„ Level 3: File Targeting"]
        F1["ğŸ“„ auth/main.py<br/>ğŸ¯ Primary authentication logic<br/>ğŸ“Š Semantic score: 0.92<br/>ğŸ” BM25 score: 0.88"]
        F2["ğŸ“„ auth/middleware.py<br/>ğŸ¯ Auth middleware functions<br/>ğŸ“Š Semantic score: 0.85<br/>ğŸ” BM25 score: 0.82"]
    end
    
    Q --> C1
    Q -.-> C2
    Q -.-> C3
    C1 --> S1
    C1 --> S2
    C1 --> S3
    S1 --> F1
    S1 --> F2
    
    classDef query fill:#e3f2fd,stroke:#2196f3,stroke-width:3px,color:#000
    classDef relevant fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000
    classDef irrelevant fill:#f5f5f5,stroke:#9e9e9e,stroke-width:1px,color:#666
    classDef structure fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef file fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px,color:#000

    class Q query
    class C1 relevant
    class C2,C3 irrelevant
    class S1,S2,S3 structure
    class F1,F2 file
```

### Performance Comparison: Brute Force vs Intelligent Navigation

| Approach | Files Scanned | Time | Accuracy | Cache Benefit |
|----------|---------------|------|----------|---------------|
| **ğŸŒ Brute Force** | 1,000+ files | 30-60 seconds | Variable | None |
| **ğŸ§  MCP Capsules** | 5-10 files | 0.5-2 seconds | High | 95%+ cache hit |

### The Caching Workflow in Detail

```mermaid
flowchart TB
    subgraph Bootstrap ["ğŸš€ Bootstrap Phase (Once per App)"]
        direction TB
        
        Discover["ğŸ” Discover App<br/>ğŸ“ /workspace/auth-service"]
        --> Analyze["ğŸ§  AI Analysis<br/>ğŸ“„ Scan representative files<br/>ğŸ¯ Extract purpose<br/>ğŸ“Š Classify role"]
        --> Build["ğŸ­ Build Capsule<br/>ğŸ“ Metadata extraction<br/>ğŸšª Find entrypoints<br/>ğŸ§ª Locate tests<br/>ğŸ“š Index docs"]
        --> Cache["ğŸ’¾ Cache to Disk<br/>ğŸ’¾ cache/capsule_auth.json<br/>ğŸ§  Load to memory<br/>ğŸ“‡ Build search index"]
    end
    
    subgraph Runtime ["âš¡ Runtime Phase (Every Query)"]
        direction TB
        
        AIQuery["ğŸ¤– AI Query<br/>'authentication logic'"]
        --> CacheCheck["ğŸ” Cache Lookup<br/>âš¡ 0.001s lookup<br/>ğŸ“¦ Load capsule<br/>ğŸ“‡ Use search index"]
        --> SmartFilter["ğŸ§  Smart Filtering<br/>ğŸ¯ Purpose matching<br/>ğŸ“Š Relevance scoring<br/>ğŸ” Semantic ranking"]
        --> DirectTarget["ğŸ¯ Direct Targeting<br/>ğŸ“„ auth/main.py<br/>ğŸ“„ auth/middleware.py<br/>âš¡ 0.1s total time"]
    end
    
    Cache -.-> CacheCheck
    
    classDef bootstrap fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef runtime fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000
    classDef cache fill:#f1f8e9,stroke:#795548,stroke-width:2px,color:#000
    classDef target fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000

    class Discover,Analyze,Build bootstrap
    class AIQuery,CacheCheck,SmartFilter runtime
    class Cache cache
    class DirectTarget target
```

## ğŸ“Š Capsule Metadata: The Intelligence Behind Fast Queries

### What's Inside a Capsule (Real Example)

```mermaid
flowchart LR
    subgraph CapsuleFile ["ğŸ’¾ cache/capsule_auth_service.json"]
        direction TB
        
        subgraph Meta ["ğŸ“‹ Core Metadata"]
            Purpose["ğŸ¯ Purpose<br/>'User authentication and session management'"]
            Generated["ğŸ“… Generated<br/>'2024-09-10T12:34:56Z'"]
            Budget["ğŸ’° Token Budget<br/>1200 tokens"]
        end
        
        subgraph Structure ["ğŸ—ï¸ App Structure"]
            Entry["ğŸšª Entrypoints<br/>['auth/main.py', 'auth/cli.py']"]
            Modules["ğŸ“¦ Key Modules<br/>['auth/models.py', 'auth/utils.py']"]
            Tests["ğŸ§ª Hot Tests<br/>['tests/auth/test_login.py']"]
            Docs["ğŸ“š Documentation<br/>['docs/auth.md', 'README.md']"]
        end
        
        subgraph AI ["ğŸ¤– AI Analysis"]
            Role["ğŸ·ï¸ Role: 'authentication'"]
            Confidence["ğŸ“Š Confidence: 0.85"]
            Evidence["ğŸ“„ Evidence Paths<br/>['auth/main.py', 'auth/models.py']"]
        end
    end
    
    subgraph Usage ["ğŸ” How AI Uses This"]
        Query["ğŸ¤– Query: 'authentication'"]
        --> Match["ğŸ¯ Purpose Match: 95%"]
        --> Navigate["ğŸ§­ Navigate to Entrypoints"]
        --> Rank["ğŸ“Š Rank by Confidence"]
        --> Result["âš¡ Return: auth/main.py<br/>ğŸ• Total time: 0.1s"]
    end
    
    CapsuleFile -.-> Usage
    
    classDef metadata fill:#e3f2fd,stroke:#2196f3,stroke-width:2px,color:#000
    classDef structure fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef ai fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px,color:#000
    classDef usage fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000

    class Meta,Purpose,Generated,Budget metadata
    class Structure,Entry,Modules,Tests,Docs structure
    class AI,Role,Confidence,Evidence ai
    class Query,Match,Navigate,Rank,Result usage
```

### Cache Hit vs Cache Miss: The Performance Impact

```mermaid
flowchart LR
    subgraph CacheHit ["âœ… Cache Hit (95% of queries)"]
        direction TB
        QH["ğŸ¤– AI Query"]
        --> LoadH["ğŸ“¦ Load Capsule<br/>âš¡ 0.001s"]
        --> SearchH["ğŸ” Search Index<br/>âš¡ 0.05s"]
        --> ResultH["ğŸ¯ Result<br/>âš¡ 0.1s total"]
    end
    
    subgraph CacheMiss ["âŒ Cache Miss (5% of queries)"]
        direction TB
        QM["ğŸ¤– AI Query"]
        --> ScanM["ğŸ” Full Scan<br/>â±ï¸ 2-5s"]
        --> AnalyzeM["ğŸ§  AI Analysis<br/>â±ï¸ 3-10s"]
        --> BuildM["ğŸ­ Build Capsule<br/>â±ï¸ 1-2s"]
        --> CacheM["ğŸ’¾ Cache Result<br/>â±ï¸ 0.1s"]
        --> ResultM["ğŸ¯ Result<br/>â±ï¸ 6-17s total"]
    end
    
    classDef hit fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000
    classDef miss fill:#ffebee,stroke:#f44336,stroke-width:2px,color:#000
    classDef fast fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000
    classDef slow fill:#ffcdd2,stroke:#f44336,stroke-width:3px,color:#000

    class QH,LoadH,SearchH hit
    class QM,ScanM,AnalyzeM,BuildM,CacheM miss
    class ResultH fast
    class ResultM slow
```

### Detailed Sequence

```mermaid
sequenceDiagram
    participant C as ğŸ’» MCP Client
    participant S as ğŸ§  Workspace MCP
    participant Sc as ğŸ” App Scanner
    participant Q as ğŸ“‹ Job Queue
    participant G as ğŸ­ Capsule Generator
    participant Ca as ğŸ’¾ Capsule Cache
    participant M as ğŸ§  Capsule Memory
    participant I as ğŸ“‡ Search Index

    C->>S: initialize()
    S->>Sc: listAppRoots()
    Sc-->>S: app paths
    S->>Q: enqueue(apps)
    
    rect rgb(240, 248, 255)
        Note over Q,Ca: Queue Processing Loop
        Q->>G: processOne(app)
        alt Non-git path
            G->>G: ensure metadata (.capsule.json)
        end
        G->>Ca: write capsule_*.json
        G->>M: update in-memory capsule
        M->>I: build Lunr index (first time)
    end

    C->>S: tools/call workspace.search_semantic
    S->>I: search BM25
    alt mode != bm25
        S->>I: semantic rerank (optional)
    end
    S-->>C: ranked items + previews
```

### Boot Sequence (From Zero â†’ Ready)

```mermaid
flowchart LR
    Start(["ğŸš€ Start"]) --> ReadCfg["ğŸ“– Read config.json"]
    ReadCfg --> Discover["ğŸ” listAppRoots()"]
    Discover --> Enqueue["ğŸ“‹ Seed jobs for apps"]
    Enqueue --> Pump["âš¡ pumpQueue()"]
    Pump --> Proc["ğŸ­ processOne(app)"]
    Proc -->|non-git| Meta["ğŸ“ ensure .capsule.json"]
    Proc --> Summ["ğŸ§  Summarize app"]
    Summ --> Cache["ğŸ’¾ Write capsule cache"]
    Summ --> Mem["ğŸ§  Update in-memory capsule"]
    Mem --> Lunr["ğŸ“‡ Build Lunr index"]
    Lunr --> Watch["ğŸ‘ï¸ Start file watchers"]
    Watch --> Ready(["âœ… Ready"])

    classDef startEnd fill:#e8f5e8,stroke:#333,stroke-width:3px,color:#000
    classDef config fill:#e1f5fe,stroke:#333,stroke-width:2px,color:#000
    classDef queue fill:#fff3e0,stroke:#333,stroke-width:2px,color:#000
    classDef process fill:#ede7f6,stroke:#333,stroke-width:2px,color:#000
    classDef storage fill:#f1f8e9,stroke:#333,stroke-width:2px,color:#000
    classDef search fill:#e3f2fd,stroke:#333,stroke-width:2px,color:#000
    classDef watch fill:#fce4ec,stroke:#333,stroke-width:2px,color:#000

    class Start,Ready startEnd
    class ReadCfg,Discover config
    class Enqueue,Pump queue
    class Proc,Summ process
    class Meta,Cache,Mem storage
    class Lunr search
    class Watch watch
```

Summary of relationships:
- The scanner discovers app roots using `appGlobs` and `ignore`.
- Each app becomes a capsule job; jobs are rate-limited and prioritized.
- Non-Git apps get a `.capsule.json` metadata file to guide indexing.
- Summaries populate the in-memory capsule and persist to the cache.
- The first time an app is seen, a Lunr index is built and reused.
- Watchers debounce file changes and enqueue incremental updates.

---

## Configuration Reference

`config.json` keys and impact:

- **workspaceRoot**: absolute path boundary for all operations; paths are validated to stay inside this root.
- **appGlobs**: patterns used by the scanner to discover app roots. Each discovered app becomes a unit for capsule building and indexing.
- **ignore**: `picomatch` patterns excluded everywhere (scanner, indexer, watchers).
- **queue**:
  - `maxConcurrentSummaries`: number of parallel capsule jobs.
  - `summariesPerMinute`: drip rate to avoid spikes.
  - `debounceMs`: coalesce file events before enqueue.
  - `priorityPaths`: any app path starting with these receives higher priority.
- **purpose**:
  - `limits`: default budgets for non-git apps (maxFiles, maxBytes, timeout).
  - `gitRepoOverrides`: larger budgets when inside a Git repo.
- **activity**:
  - `enable`: if true, promotes recently active subtrees.
  - `sources`: `cursorIde`, `cursorSessions`, `fsMtime` control which signals are used.
  - `promote`: thresholds controlling promotion density.

---

## Tooling Reference (MCP)

All tools are registered under the `workspace.*` namespace:

- `workspace.list_roots` â†’ returns discovered app roots
- `workspace.list_apps` â†’ returns apps with built capsules in memory
- `workspace.find_app(name, limit)` â†’ fuzzy match app by name/rel path
- `workspace.bootstrap(app, intent?, force?)` â†’ build or refresh capsule for `app` (uses cache when available)
- `workspace.list_entrypoints(app)` â†’ list detected entrypoints for `app`
- `workspace.describe_symbol(path)` â†’ file head and top-level definitions (safe for large files)
- `workspace.tests_for(app?)` â†’ hot test files for the app (if any)
- `workspace.owners(path?)` â†’ placeholder ownership info
- `workspace.search_semantic(query, app?, top_k?, min_score?, mode?)` â†’ hybrid/BM25/semantic search

Search modes:
- `bm25` â†’ keyword only
- `semantic` â†’ embeddings only
- `hybrid` (default) â†’ `score = 0.7 * semantic + 0.3 * bm25`

---

## Caching & Persistence

- Capsules are persisted to `cache/capsule_<hex(appPath)>.json`.
- On startup, the server enqueues existing apps and rebuilds capsules incrementally.
- When tools like `workspace.bootstrap` are called, the cache is checked first; only missing/stale pieces are recomputed.
- Telemetry is appended to `cache/telemetry.log` for troubleshooting.

```mermaid
flowchart LR
    subgraph App ["ğŸ“ Application"]
        SRC["ğŸ“„ Source Files"]
        META["ğŸ“ .capsule.json"]
    end
    
    SRC --> GEN["ğŸ§  AI Summarize"]
    META --> GEN
    GEN --> MEM[("ğŸ§  Capsule Memory")]
    GEN --> DISK[("ğŸ’¾ Capsule Cache")]
    MEM --> LUNR[("ğŸ“‡ Lunr Index")]
    LUNR --> QRY["ğŸ” Query"]
    QRY --> RES["ğŸ“Š Ranked Results"]

    classDef generator fill:#f3e5f5,stroke:#333,stroke-width:2px,color:#000
    classDef memory fill:#e1f5fe,stroke:#333,stroke-width:2px,color:#000
    classDef storage fill:#f1f8e9,stroke:#333,stroke-width:2px,color:#000
    classDef search fill:#fff3e0,stroke:#333,stroke-width:2px,color:#000
    classDef query fill:#fce4ec,stroke:#333,stroke-width:2px,color:#000

    class GEN generator
    class MEM memory
    class DISK storage
    class LUNR search
    class QRY,RES query
```

---

## Git vs Nonâ€‘Git Apps and AI Summarization

### Behavior Summary

| Context | Metadata (.capsule.json) | Budgets Used | AI Summarization | Notes |
|---|---|---|---|---|
| Nonâ€‘Git app path | Created (once) | `purpose.limits` | Yes (local stub by default) | Guides indexing for nonâ€‘repo code |
| Git repo path | Not created | `purpose.gitRepoOverrides` | Yes (local stub by default) | Larger budgets for repos |

Key points:
- The system checks if an app is inside a Git repo to decide two things: whether to create lightweight metadata, and which resource budgets to apply.
- Both Git and nonâ€‘Git apps are summarized into capsules and cached.
- By default, external AI summarization is ENABLED. It can be disabled with env flags at any time.

Code references:

```58:116:/Users/ashafi/Documents/work/tools/workspace-mcp/index.js
const DEFAULT_WORKSPACE_ROOT = '/Users/ashafi/Documents/work';
...
async function aiSummarizeApp(appPath, limits) {
  // Minimal stub: collect small representative snippets; call no external model yet.
  // In your environment, wire to MCP sampling client here.
}
```

```147:166:/Users/ashafi/Documents/work/tools/workspace-mcp/index.js
const inGit = isInsideGitRepo(job.appPath);
const limits = inGit ? PURPOSE_LIMITS.gitRepoOverrides : PURPOSE_LIMITS.limits;
if (!inGit) { await ensureMetadataFile(job.appPath); }
// Summarize â†’ write capsule cache â†’ update inâ€‘memory capsule
```

### Networking & Privacy

- External AI summarization is on by default. Disable via env (see below) if your policy requires fully local.
- If `WORKSPACE_MCP_AI_ENDPOINT` is set, it will POST representative snippets to that endpoint. Otherwise, if `OPENAI_API_KEY` is present, it will use OpenAI Chat Completions.
- If disabled or no provider is available, the system falls back to a local heuristic (no network calls).
- Telemetry is local (`cache/telemetry.log`).

### How to disable external AI

Set ONE of the following and restart:
```
export WORKSPACE_MCP_AI=disabled
# or
export WORKSPACE_MCP_AI_DISABLE=1
```

### How to configure external AI (default order: Gemini â†’ OpenAI â†’ local)

Option A: Gemini CLI (default priority)
```
export WORKSPACE_MCP_GEMINI_CLI=gemini           # or your wrapper
export WORKSPACE_MCP_GEMINI_MODEL=gemini-1.5-flash
export GOOGLE_API_KEY=your-gemini-api-key
# Optional custom args template (tokens: {MODEL}, {PROMPT})
# export WORKSPACE_MCP_GEMINI_ARGS="-m {MODEL} generate -p {PROMPT}"
```

Option B: OpenAI fallback
```
export OPENAI_API_KEY=sk-...
export WORKSPACE_MCP_AI_MODEL=gpt-4o-mini   # optional (default shown)
```

Option C: Generic HTTP endpoint (lowest priority)
```
export WORKSPACE_MCP_AI_ENDPOINT=https://your-ai-endpoint/summarize
export WORKSPACE_MCP_AI_AUTH="Bearer <TOKEN>"   # optional
```

---

## Operational Notes

- All file operations are constrained to `workspaceRoot`.
- Large files are summarized (head + signatures) to prevent heavy loads.
- Logs are not indexed by default.
- Activity promotion runs periodically when enabled.

---

## Example: End-to-End

1) Add the server in your MCP client (e.g., Cursor) with command:
```
node /path/to/workspace-mcp/index.js
```
2) Initialize config (first time):
```
npx workspace-mcp init
```
3) Start server:
```
npx workspace-mcp start
```
4) From your MCP client, call:
```
workspace.search_semantic("kubeVirt utils for Cypress")
```
â†’ The server reuses the capsule cache and Lunr index to return results quickly.


