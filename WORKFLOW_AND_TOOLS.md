## Workspace MCP: Workflows, Caching, and Tooling

This document explains, in depth, how the server discovers apps, builds metadata, generates and caches capsules, and serves fast hybrid search, along with a detailed reference for configuration and tools.

## ğŸ“ App Discovery: What Constitutes an "App"

### ğŸ” App Definition and Discovery Logic

An **"app"** in Workspace MCP is any directory that matches the configured `appGlobs` patterns and contains project-like structure. The system doesn't make assumptions about what constitutes a project - it relies on your configuration.

```mermaid
flowchart TB
    subgraph Config ["âš™ï¸ Configuration"]
        AppGlobs["ğŸ“‹ appGlobs<br/>['apps/*', 'tools/*', 'automation/*']"]
        Ignore["ğŸš« ignore<br/>['node_modules', '.git', 'dist']"]
        WorkspaceRoot["ğŸ“ workspaceRoot<br/>'/path/to/your/workspace'"]
    end
    
    subgraph Discovery ["ğŸ” Discovery Process"]
        Scan["ğŸ” Scan Workspace<br/>ğŸ“ Read workspaceRoot<br/>ğŸ” Apply appGlobs patterns<br/>ğŸš« Filter by ignore patterns"]
        
        Match["ğŸ“‹ Pattern Matching<br/>âœ… 'apps/my-service' matches 'apps/*'<br/>âœ… 'tools/cli-tool' matches 'tools/*'<br/>âŒ 'node_modules/lib' ignored"]
        
        Validate["âœ”ï¸ Validation<br/>ğŸ“ Must be directory<br/>ğŸ“‚ Must be readable<br/>ğŸ” Must exist on filesystem"]
    end
    
    subgraph Result ["ğŸ“‹ App Registry"]
        AppList["ğŸ“ Discovered Apps<br/>â€¢ /workspace/apps/auth-service<br/>â€¢ /workspace/apps/payment-api<br/>â€¢ /workspace/tools/cli-helper<br/>â€¢ /workspace/automation/scripts"]
    end
    
    Config --> Discovery
    Scan --> Match
    Match --> Validate
    Validate --> AppList
    
    classDef config fill:#e3f2fd,stroke:#2196f3,stroke-width:2px,color:#000
    classDef discovery fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef result fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000

    class AppGlobs,Ignore,WorkspaceRoot config
    class Scan,Match,Validate discovery
    class AppList result
```

### ğŸ“‹ App Discovery Examples

| appGlobs Pattern | Workspace Structure | Discovered Apps | Notes |
|------------------|---------------------|-----------------|-------|
| `"apps/*"` | `/workspace/apps/auth/`<br/>`/workspace/apps/payment/` | 2 apps:<br/>â€¢ `auth`<br/>â€¢ `payment` | Each subdirectory becomes an app |
| `"tools/*"` | `/workspace/tools/cli/`<br/>`/workspace/tools/scripts/` | 2 apps:<br/>â€¢ `cli`<br/>â€¢ `scripts` | Tools are treated as individual apps |
| `"automation"` | `/workspace/automation/` | 1 app:<br/>â€¢ `automation` | Entire directory is one app |
| `"*"` | `/workspace/projectA/`<br/>`/workspace/projectB/` | 2 apps:<br/>â€¢ `projectA`<br/>â€¢ `projectB` | Top-level scan (fallback) |

### ğŸ—ï¸ What Makes a Directory an "App"

The system considers any directory an "app" if:

1. **âœ… Matches `appGlobs` pattern** - Defined in your configuration
2. **âœ… Not in `ignore` list** - Excludes `node_modules`, `.git`, etc.
3. **âœ… Is a directory** - Files are not considered apps
4. **âœ… Is readable** - System has filesystem access

**Important**: The system does NOT require:
- `package.json` or other project files
- Specific folder structure (`src/`, `tests/`)
- README or documentation
- Any particular programming language

### ğŸ”„ App Lifecycle: From Discovery to Ready

```mermaid
flowchart LR
    Discover["ğŸ” Discovery<br/>ğŸ“‹ Match appGlobs<br/>ğŸš« Apply ignore filters<br/>âœ”ï¸ Validate existence"]
    --> Enqueue["ğŸ“‹ Enqueue<br/>ğŸ“Š Calculate priority<br/>â±ï¸ Add to job queue<br/>ğŸš¦ Rate limit"]
    --> Process["ğŸ­ Process<br/>ğŸ” Check if Git repo<br/>ğŸ“ Create metadata (non-Git)<br/>ğŸ§  AI analysis<br/>ğŸ’¾ Build capsule"]
    --> Cache["ğŸ’¾ Cache<br/>ğŸ’¾ Write to disk<br/>ğŸ§  Load to memory<br/>ğŸ“‡ Build search index"]
    --> Ready["âœ… Ready<br/>ğŸ” Available for search<br/>ğŸ› ï¸ Exposed via MCP tools<br/>ğŸ‘ï¸ Watched for changes"]
    
    classDef discover fill:#e3f2fd,stroke:#2196f3,stroke-width:2px,color:#000
    classDef queue fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef process fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px,color:#000
    classDef cache fill:#f1f8e9,stroke:#795548,stroke-width:2px,color:#000
    classDef ready fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000

    class Discover discover
    class Enqueue queue
    class Process process
    class Cache cache
    class Ready ready
```

**Key Point**: An "app" is simply **any directory your configuration tells the system to analyze**. The intelligence comes from how the system processes and understands each discovered directory.

### ğŸ’» Code Implementation: How Apps Are Discovered

```javascript
// From index.js: listAppRoots() function
function listAppRoots() {
  const results = new Set();
  for (const pattern of config.appGlobs || []) {
    const matches = fg.sync(pattern, { 
      cwd: WORKSPACE_ROOT, 
      onlyDirectories: true, 
      absolute: true, 
      dot: true, 
      ignore: config.ignore || [] 
    });
    for (const m of matches) results.add(m);
  }
  return Array.from(results);
}
```

**What this code does:**
1. **Iterates** through each pattern in `config.appGlobs`
2. **Uses fast-glob** to find matching directories
3. **Applies ignore filters** to exclude unwanted paths
4. **Returns absolute paths** of all discovered apps
5. **Deduplicates** if multiple patterns match the same directory

### ğŸ”„ When Apps Are "Created" (Processed)

Apps are **discovered once** but **processed multiple times**:

| Event | Trigger | Action | AI Usage |
|-------|---------|--------|----------|
| **ğŸš€ Server Startup** | Initial scan | Discover + enqueue all apps | âœ… AI analysis |
| **ğŸ“ File Changes** | Chokidar file watcher | Re-enqueue changed app | âœ… AI re-analysis |
| **ğŸ“Š Activity Promotion** | Every 5 minutes | Enqueue active apps | âœ… AI analysis |
| **ğŸ”§ Manual Bootstrap** | `workspace.bootstrap` call | Force refresh specific app | âœ… AI analysis |
| **ğŸ” Search Query** | `workspace.search_semantic` | Use existing capsule | âŒ No AI |

### High-Level Flow

```mermaid
graph TB
    FileSystem["ğŸ“ File System"]
    Scanner["ğŸ” Workspace Scanner"]
    Config["âš™ï¸ config.json"]
    Queue["ğŸ“‹ Job Queue"]
    Generator["ğŸ­ Capsule Generator"]
    Cache["ğŸ’¾ Capsule Cache"]
    Memory["ğŸ§  Capsule Memory"]
    Index["ğŸ“‡ Search Index"]
    Search["ğŸ” Hybrid Search"]
    Tools["ğŸ› ï¸ MCP Tools"]
    Client["ğŸ’» MCP Client"]

    FileSystem --> Scanner
    Config --> Scanner
    Scanner --> Queue
    Queue --> Generator
    Generator --> Cache
    Generator --> Memory
    Memory --> Index
    Index --> Search
    Search --> Tools
    Tools --> Client

    classDef scanner fill:#e1f5fe,stroke:#333,stroke-width:2px,color:#000
    classDef queue fill:#fff3e0,stroke:#333,stroke-width:2px,color:#000
    classDef generator fill:#f3e5f5,stroke:#333,stroke-width:2px,color:#000
    classDef storage fill:#f1f8e9,stroke:#333,stroke-width:2px,color:#000
    classDef search fill:#e3f2fd,stroke:#333,stroke-width:2px,color:#000
    classDef tools fill:#ede7f6,stroke:#333,stroke-width:2px,color:#000

    class Scanner scanner
    class Queue queue
    class Generator generator
    class Cache,Memory storage
    class Index,Search search
    class Tools tools
```

## ğŸ§  Capsule-Based Architecture: Optimizing AI Service Performance

### The Problem: Brute Force Workspace Scanning

Without MCP, AI services face this challenge every time:

```mermaid
flowchart TB
    subgraph Workspace ["ğŸ“ Raw Workspace (Thousands of Files)"]
        App1["ğŸ“ App 1<br/>â”œâ”€â”€ src/ (50 files)<br/>â”œâ”€â”€ tests/ (30 files)<br/>â”œâ”€â”€ docs/ (10 files)<br/>â””â”€â”€ â“ Purpose unknown"]
        App2["ğŸ“ App 2<br/>â”œâ”€â”€ components/ (200 files)<br/>â”œâ”€â”€ utils/ (40 files)<br/>â”œâ”€â”€ styles/ (60 files)<br/>â””â”€â”€ â“ Purpose unknown"]
        App3["ğŸ“ App 3<br/>â”œâ”€â”€ modules/ (80 files)<br/>â”œâ”€â”€ config/ (15 files)<br/>â”œâ”€â”€ scripts/ (25 files)<br/>â””â”€â”€ â“ Purpose unknown"]
        AppN["ğŸ“ ... App N<br/>â”œâ”€â”€ â“ Unknown structure<br/>â””â”€â”€ â“ Unknown purpose"]
    end
    
    AI["ğŸ¤– AI Service"] --> Scan1["ğŸ” Scan App 1<br/>â±ï¸ Read 90 files<br/>ğŸ§  Analyze purpose<br/>ğŸ“ Understand structure"]
    AI --> Scan2["ğŸ” Scan App 2<br/>â±ï¸ Read 300 files<br/>ğŸ§  Analyze purpose<br/>ğŸ“ Understand structure"]
    AI --> Scan3["ğŸ” Scan App 3<br/>â±ï¸ Read 120 files<br/>ğŸ§  Analyze purpose<br/>ğŸ“ Understand structure"]
    AI --> ScanN["ğŸ” Scan App N<br/>â±ï¸ Read ??? files<br/>ğŸ§  Analyze purpose<br/>ğŸ“ Understand structure"]
    
    Scan1 --> Slow["ğŸŒ SLOW RESULT<br/>â±ï¸ Minutes per query<br/>ğŸ’¸ High compute cost<br/>ğŸ”„ Repeated work"]
    Scan2 --> Slow
    Scan3 --> Slow
    ScanN --> Slow

    classDef workspace fill:#ffebee,stroke:#d32f2f,stroke-width:2px,color:#000
    classDef ai fill:#e3f2fd,stroke:#333,stroke-width:2px,color:#000
    classDef scan fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef slow fill:#ffcdd2,stroke:#d32f2f,stroke-width:3px,color:#000

    class App1,App2,App3,AppN workspace
    class AI ai
    class Scan1,Scan2,Scan3,ScanN scan
    class Slow slow
```

### The Solution: Intelligent Capsule-Based Navigation

With MCP, AI services get a **pre-computed intelligence layer**:

```mermaid
flowchart TB
    subgraph MCP ["ğŸ§  MCP Intelligence Layer"]
        direction TB
        
        subgraph Capsules ["ğŸ“¦ Smart Capsules (Pre-computed)"]
            Cap1["ğŸ“¦ App 1 Capsule<br/>ğŸ¯ Purpose: 'User authentication service'<br/>ğŸšª Entry: auth/main.py<br/>ğŸ§ª Tests: tests/auth/<br/>ğŸ“š Docs: docs/auth.md<br/>âš¡ Ready to query"]
            
            Cap2["ğŸ“¦ App 2 Capsule<br/>ğŸ¯ Purpose: 'React UI components library'<br/>ğŸšª Entry: src/index.tsx<br/>ğŸ§ª Tests: __tests__/<br/>ğŸ“š Docs: README.md<br/>âš¡ Ready to query"]
            
            Cap3["ğŸ“¦ App 3 Capsule<br/>ğŸ¯ Purpose: 'Payment processing API'<br/>ğŸšª Entry: server/app.js<br/>ğŸ§ª Tests: tests/integration/<br/>ğŸ“š Docs: docs/api.md<br/>âš¡ Ready to query"]
        end
        
        subgraph Indexes ["ğŸ“‡ Search Indexes (Pre-built)"]
            Idx1["ğŸ“‡ App 1 Index<br/>ğŸ” BM25 + Semantic<br/>ğŸ“Š Ranked relevance<br/>âš¡ Instant lookup"]
            Idx2["ğŸ“‡ App 2 Index<br/>ğŸ” BM25 + Semantic<br/>ğŸ“Š Ranked relevance<br/>âš¡ Instant lookup"]
            Idx3["ğŸ“‡ App 3 Index<br/>ğŸ” BM25 + Semantic<br/>ğŸ“Š Ranked relevance<br/>âš¡ Instant lookup"]
        end
    end
    
    AI["ğŸ¤– AI Service"] --> Smart["ğŸ§  Smart Query:<br/>'Where is user authentication?'"]
    Smart --> Cap1
    Cap1 --> Target["ğŸ¯ Direct to: auth/main.py<br/>âš¡ Instant result<br/>ğŸ“Š High confidence<br/>ğŸ¯ Precise targeting"]
    
    AI2["ğŸ¤– AI Service"] --> Smart2["ğŸ§  Smart Query:<br/>'How does payment work?'"]
    Smart2 --> Cap3
    Cap3 --> Target2["ğŸ¯ Direct to: server/app.js<br/>âš¡ Instant result<br/>ğŸ“Š High confidence<br/>ğŸ¯ Precise targeting"]

    classDef capsule fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000
    classDef index fill:#e3f2fd,stroke:#2196f3,stroke-width:2px,color:#000
    classDef ai fill:#fff3e0,stroke:#333,stroke-width:2px,color:#000
    classDef smart fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px,color:#000
    classDef target fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000

    class Cap1,Cap2,Cap3 capsule
    class Idx1,Idx2,Idx3 index
    class AI,AI2 ai
    class Smart,Smart2 smart
    class Target,Target2 target
```

**Key Insight**: Instead of scanning thousands of files every time, the AI service navigates through **intelligent capsules** that already know each app's purpose, structure, and key files.

## ğŸ—‚ï¸ Hierarchical Navigation: From Concept to File

### How AI Services Navigate the Workspace Hierarchy

```mermaid
flowchart LR
    subgraph Query ["ğŸ” AI Query Process"]
        Q["ğŸ¤– AI Query:<br/>'Where is authentication handled?'"]
    end
    
    subgraph Level1 ["ğŸŒŸ Level 1: Capsule Discovery"]
        C1["ğŸ“¦ Auth Service<br/>ğŸ¯ Purpose: 'User authentication'<br/>â­ Relevance: 95%"]
        C2["ğŸ“¦ UI Components<br/>ğŸ¯ Purpose: 'React components'<br/>â­ Relevance: 15%"]
        C3["ğŸ“¦ Payment API<br/>ğŸ¯ Purpose: 'Payment processing'<br/>â­ Relevance: 5%"]
    end
    
    subgraph Level2 ["ğŸ“‚ Level 2: Structure Navigation"]
        S1["ğŸšª Entrypoints:<br/>â€¢ auth/main.py<br/>â€¢ auth/middleware.py"]
        S2["ğŸ§ª Tests:<br/>â€¢ tests/auth/test_login.py<br/>â€¢ tests/auth/test_tokens.py"]
        S3["ğŸ“š Docs:<br/>â€¢ docs/authentication.md<br/>â€¢ README.md"]
    end
    
    subgraph Level3 ["ğŸ“„ Level 3: File Targeting"]
        F1["ğŸ“„ auth/main.py<br/>ğŸ¯ Primary authentication logic<br/>ğŸ“Š Semantic score: 0.92<br/>ğŸ” BM25 score: 0.88"]
        F2["ğŸ“„ auth/middleware.py<br/>ğŸ¯ Auth middleware functions<br/>ğŸ“Š Semantic score: 0.85<br/>ğŸ” BM25 score: 0.82"]
    end
    
    Q --> C1
    Q -.-> C2
    Q -.-> C3
    C1 --> S1
    C1 --> S2
    C1 --> S3
    S1 --> F1
    S1 --> F2
    
    classDef query fill:#e3f2fd,stroke:#2196f3,stroke-width:3px,color:#000
    classDef relevant fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000
    classDef irrelevant fill:#f5f5f5,stroke:#9e9e9e,stroke-width:1px,color:#666
    classDef structure fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef file fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px,color:#000

    class Q query
    class C1 relevant
    class C2,C3 irrelevant
    class S1,S2,S3 structure
    class F1,F2 file
```

### Performance Comparison: Brute Force vs Intelligent Navigation

| Approach | Files Scanned | Time | Accuracy | Cache Benefit |
|----------|---------------|------|----------|---------------|
| **ğŸŒ Brute Force** | 1,000+ files | 30-60 seconds | Variable | None |
| **ğŸ§  MCP Capsules** | 5-10 files | 0.5-2 seconds | High | 95%+ cache hit |

### The Caching Workflow in Detail

```mermaid
flowchart TB
    subgraph Bootstrap ["ğŸš€ Bootstrap Phase (Once per App)"]
        direction TB
        
        Discover["ğŸ” Discover App<br/>ğŸ“ /workspace/auth-service"]
        --> Analyze["ğŸ§  AI Analysis<br/>ğŸ“„ Scan representative files<br/>ğŸ¯ Extract purpose<br/>ğŸ“Š Classify role"]
        --> Build["ğŸ­ Build Capsule<br/>ğŸ“ Metadata extraction<br/>ğŸšª Find entrypoints<br/>ğŸ§ª Locate tests<br/>ğŸ“š Index docs"]
        --> Cache["ğŸ’¾ Cache to Disk<br/>ğŸ’¾ cache/capsule_auth.json<br/>ğŸ§  Load to memory<br/>ğŸ“‡ Build search index"]
    end
    
    subgraph Runtime ["âš¡ Runtime Phase (Every Query)"]
        direction TB
        
        AIQuery["ğŸ¤– AI Query<br/>'authentication logic'"]
        --> CacheCheck["ğŸ” Cache Lookup<br/>âš¡ 0.001s lookup<br/>ğŸ“¦ Load capsule<br/>ğŸ“‡ Use search index"]
        --> SmartFilter["ğŸ§  Smart Filtering<br/>ğŸ¯ Purpose matching<br/>ğŸ“Š Relevance scoring<br/>ğŸ” Semantic ranking"]
        --> DirectTarget["ğŸ¯ Direct Targeting<br/>ğŸ“„ auth/main.py<br/>ğŸ“„ auth/middleware.py<br/>âš¡ 0.1s total time"]
    end
    
    Cache -.-> CacheCheck
    
    classDef bootstrap fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef runtime fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000
    classDef cache fill:#f1f8e9,stroke:#795548,stroke-width:2px,color:#000
    classDef target fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000

    class Discover,Analyze,Build bootstrap
    class AIQuery,CacheCheck,SmartFilter runtime
    class Cache cache
    class DirectTarget target
```

## ğŸ“Š Capsule Metadata: The Intelligence Behind Fast Queries

### What's Inside a Capsule (Real Example)

```mermaid
flowchart LR
    subgraph CapsuleFile ["ğŸ’¾ cache/capsule_auth_service.json"]
        direction TB
        
        subgraph Meta ["ğŸ“‹ Core Metadata"]
            Purpose["ğŸ¯ Purpose<br/>'User authentication and session management'"]
            Generated["ğŸ“… Generated<br/>'2024-09-10T12:34:56Z'"]
            Budget["ğŸ’° Token Budget<br/>1200 tokens"]
        end
        
        subgraph Structure ["ğŸ—ï¸ App Structure"]
            Entry["ğŸšª Entrypoints<br/>['auth/main.py', 'auth/cli.py']"]
            Modules["ğŸ“¦ Key Modules<br/>['auth/models.py', 'auth/utils.py']"]
            Tests["ğŸ§ª Hot Tests<br/>['tests/auth/test_login.py']"]
            Docs["ğŸ“š Documentation<br/>['docs/auth.md', 'README.md']"]
        end
        
        subgraph AI ["ğŸ¤– AI Analysis"]
            Role["ğŸ·ï¸ Role: 'authentication'"]
            Confidence["ğŸ“Š Confidence: 0.85"]
            Evidence["ğŸ“„ Evidence Paths<br/>['auth/main.py', 'auth/models.py']"]
        end
    end
    
    subgraph Usage ["ğŸ” How AI Uses This"]
        Query["ğŸ¤– Query: 'authentication'"]
        --> Match["ğŸ¯ Purpose Match: 95%"]
        --> Navigate["ğŸ§­ Navigate to Entrypoints"]
        --> Rank["ğŸ“Š Rank by Confidence"]
        --> Result["âš¡ Return: auth/main.py<br/>ğŸ• Total time: 0.1s"]
    end
    
    CapsuleFile -.-> Usage
    
    classDef metadata fill:#e3f2fd,stroke:#2196f3,stroke-width:2px,color:#000
    classDef structure fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef ai fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px,color:#000
    classDef usage fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000

    class Meta,Purpose,Generated,Budget metadata
    class Structure,Entry,Modules,Tests,Docs structure
    class AI,Role,Confidence,Evidence ai
    class Query,Match,Navigate,Rank,Result usage
```

### Cache Hit vs Cache Miss: The Performance Impact

```mermaid
flowchart LR
    subgraph CacheHit ["âœ… Cache Hit (95% of queries)"]
        direction TB
        QH["ğŸ¤– AI Query"]
        --> LoadH["ğŸ“¦ Load Capsule<br/>âš¡ 0.001s"]
        --> SearchH["ğŸ” Search Index<br/>âš¡ 0.05s"]
        --> ResultH["ğŸ¯ Result<br/>âš¡ 0.1s total"]
    end
    
    subgraph CacheMiss ["âŒ Cache Miss (5% of queries)"]
        direction TB
        QM["ğŸ¤– AI Query"]
        --> ScanM["ğŸ” Full Scan<br/>â±ï¸ 2-5s"]
        --> AnalyzeM["ğŸ§  AI Analysis<br/>â±ï¸ 3-10s"]
        --> BuildM["ğŸ­ Build Capsule<br/>â±ï¸ 1-2s"]
        --> CacheM["ğŸ’¾ Cache Result<br/>â±ï¸ 0.1s"]
        --> ResultM["ğŸ¯ Result<br/>â±ï¸ 6-17s total"]
    end
    
    classDef hit fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000
    classDef miss fill:#ffebee,stroke:#f44336,stroke-width:2px,color:#000
    classDef fast fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000
    classDef slow fill:#ffcdd2,stroke:#f44336,stroke-width:3px,color:#000

    class QH,LoadH,SearchH hit
    class QM,ScanM,AnalyzeM,BuildM,CacheM miss
    class ResultH fast
    class ResultM slow
```

### Detailed Sequence

```mermaid
sequenceDiagram
    participant C as ğŸ’» MCP Client
    participant S as ğŸ§  Workspace MCP
    participant Sc as ğŸ” App Scanner
    participant Q as ğŸ“‹ Job Queue
    participant G as ğŸ­ Capsule Generator
    participant Ca as ğŸ’¾ Capsule Cache
    participant M as ğŸ§  Capsule Memory
    participant I as ğŸ“‡ Search Index

    C->>S: initialize()
    S->>Sc: listAppRoots()
    Sc-->>S: app paths
    S->>Q: enqueue(apps)
    
    rect rgb(240, 248, 255)
        Note over Q,Ca: Queue Processing Loop
        Q->>G: processOne(app)
        alt Non-git path
            G->>G: ensure metadata (.capsule.json)
        end
        G->>Ca: write capsule_*.json
        G->>M: update in-memory capsule
        M->>I: build Lunr index (first time)
    end

    C->>S: tools/call workspace.search_semantic
    S->>I: search BM25
    alt mode != bm25
        S->>I: semantic rerank (optional)
    end
    S-->>C: ranked items + previews
```

### Boot Sequence (From Zero â†’ Ready)

```mermaid
flowchart LR
    Start(["ğŸš€ Start"]) --> ReadCfg["ğŸ“– Read config.json"]
    ReadCfg --> Discover["ğŸ” listAppRoots()"]
    Discover --> Enqueue["ğŸ“‹ Seed jobs for apps"]
    Enqueue --> Pump["âš¡ pumpQueue()"]
    Pump --> Proc["ğŸ­ processOne(app)"]
    Proc -->|non-git| Meta["ğŸ“ ensure .capsule.json"]
    Proc --> Summ["ğŸ§  Summarize app"]
    Summ --> Cache["ğŸ’¾ Write capsule cache"]
    Summ --> Mem["ğŸ§  Update in-memory capsule"]
    Mem --> Lunr["ğŸ“‡ Build Lunr index"]
    Lunr --> Watch["ğŸ‘ï¸ Start file watchers"]
    Watch --> Ready(["âœ… Ready"])

    classDef startEnd fill:#e8f5e8,stroke:#333,stroke-width:3px,color:#000
    classDef config fill:#e1f5fe,stroke:#333,stroke-width:2px,color:#000
    classDef queue fill:#fff3e0,stroke:#333,stroke-width:2px,color:#000
    classDef process fill:#ede7f6,stroke:#333,stroke-width:2px,color:#000
    classDef storage fill:#f1f8e9,stroke:#333,stroke-width:2px,color:#000
    classDef search fill:#e3f2fd,stroke:#333,stroke-width:2px,color:#000
    classDef watch fill:#fce4ec,stroke:#333,stroke-width:2px,color:#000

    class Start,Ready startEnd
    class ReadCfg,Discover config
    class Enqueue,Pump queue
    class Proc,Summ process
    class Meta,Cache,Mem storage
    class Lunr search
    class Watch watch
```

Summary of relationships:
- The scanner discovers app roots using `appGlobs` and `ignore`.
- Each app becomes a capsule job; jobs are rate-limited and prioritized.
- Non-Git apps get a `.capsule.json` metadata file to guide indexing.
- Summaries populate the in-memory capsule and persist to the cache.
- The first time an app is seen, a Lunr index is built and reused.
- Watchers debounce file changes and enqueue incremental updates.

---

## Configuration Reference

`config.json` keys and impact:

- **workspaceRoot**: absolute path boundary for all operations; paths are validated to stay inside this root.
- **appGlobs**: patterns used by the scanner to discover app roots. Each discovered app becomes a unit for capsule building and indexing.
- **ignore**: `picomatch` patterns excluded everywhere (scanner, indexer, watchers).
- **queue**:
  - `maxConcurrentSummaries`: number of parallel capsule jobs.
  - `summariesPerMinute`: drip rate to avoid spikes.
  - `debounceMs`: coalesce file events before enqueue.
  - `priorityPaths`: any app path starting with these receives higher priority.
- **purpose**:
  - `limits`: default budgets for non-git apps (maxFiles, maxBytes, timeout).
  - `gitRepoOverrides`: larger budgets when inside a Git repo.
- **activity**:
  - `enable`: if true, promotes recently active subtrees.
  - `sources`: `cursorIde`, `cursorSessions`, `fsMtime` control which signals are used.
  - `promote`: thresholds controlling promotion density.

---

## Tooling Reference (MCP)

All tools are registered under the `workspace.*` namespace:

- `workspace.list_roots` â†’ returns discovered app roots
- `workspace.list_apps` â†’ returns apps with built capsules in memory
- `workspace.find_app(name, limit)` â†’ fuzzy match app by name/rel path
- `workspace.bootstrap(app, intent?, force?)` â†’ build or refresh capsule for `app` (uses cache when available)
- `workspace.list_entrypoints(app)` â†’ list detected entrypoints for `app`
- `workspace.describe_symbol(path)` â†’ file head and top-level definitions (safe for large files)
- `workspace.tests_for(app?)` â†’ hot test files for the app (if any)
- `workspace.owners(path?)` â†’ placeholder ownership info
- `workspace.search_semantic(query, app?, top_k?, min_score?, mode?)` â†’ hybrid/BM25/semantic search

Search modes:
- `bm25` â†’ keyword only
- `semantic` â†’ embeddings only
- `hybrid` (default) â†’ `score = 0.7 * semantic + 0.3 * bm25`

---

## Caching & Persistence

- Capsules are persisted to `cache/capsule_<hex(appPath)>.json`.
- On startup, the server enqueues existing apps and rebuilds capsules incrementally.
- When tools like `workspace.bootstrap` are called, the cache is checked first; only missing/stale pieces are recomputed.
- Telemetry is appended to `cache/telemetry.log` for troubleshooting.

```mermaid
flowchart LR
    subgraph App ["ğŸ“ Application"]
        SRC["ğŸ“„ Source Files"]
        META["ğŸ“ .capsule.json"]
    end
    
    SRC --> GEN["ğŸ§  AI Summarize"]
    META --> GEN
    GEN --> MEM[("ğŸ§  Capsule Memory")]
    GEN --> DISK[("ğŸ’¾ Capsule Cache")]
    MEM --> LUNR[("ğŸ“‡ Lunr Index")]
    LUNR --> QRY["ğŸ” Query"]
    QRY --> RES["ğŸ“Š Ranked Results"]

    classDef generator fill:#f3e5f5,stroke:#333,stroke-width:2px,color:#000
    classDef memory fill:#e1f5fe,stroke:#333,stroke-width:2px,color:#000
    classDef storage fill:#f1f8e9,stroke:#333,stroke-width:2px,color:#000
    classDef search fill:#fff3e0,stroke:#333,stroke-width:2px,color:#000
    classDef query fill:#fce4ec,stroke:#333,stroke-width:2px,color:#000

    class GEN generator
    class MEM memory
    class DISK storage
    class LUNR search
    class QRY,RES query
```

---

## ğŸ” When AI Services Are Used vs Not Used: The Complete Guide

### ğŸ§  AI Usage Decision Tree

```mermaid
flowchart TB
    Start["ğŸš€ App Processing Triggered"]
    --> CheckDisabled{"âŒ AI Disabled?<br/>(WORKSPACE_MCP_AI=disabled)"}
    
    CheckDisabled -->|Yes| LocalOnly["ğŸ  Local Heuristic Only<br/>ğŸ“ Extract from README/package.json<br/>ğŸšª Find entrypoints<br/>ğŸ§ª Locate tests<br/>âš¡ Fast, no network calls"]
    
    CheckDisabled -->|No| CheckGit{"ğŸ“ Git Repo?<br/>(has .git folder)"}
    
    CheckGit -->|Non-Git| NonGit["ğŸ“ Non-Git Path<br/>ğŸ’¾ Create .capsule.json<br/>ğŸ“Š Use purpose.limits<br/>ğŸ§  Try AI summarization"]
    
    CheckGit -->|Git Repo| GitRepo["ğŸ“‚ Git Repository<br/>âŒ No .capsule.json<br/>ğŸ“Š Use gitRepoOverrides<br/>ğŸ§  Try AI summarization"]
    
    NonGit --> TryAI["ğŸ¤– Attempt AI Summarization"]
    GitRepo --> TryAI
    
    TryAI --> CheckAPI{"ğŸ”‘ API Available?<br/>(GOOGLE_API_KEY or OPENAI_API_KEY)"}
    
    CheckAPI -->|Yes| AISuccess["âœ… AI Summarization<br/>ğŸ§  Gemini/OpenAI analysis<br/>ğŸ¯ Intelligent purpose extraction<br/>ğŸ“Š Confidence scoring"]
    
    CheckAPI -->|No| AIFallback["ğŸ  Fallback to Local<br/>ğŸ“ Heuristic extraction<br/>ğŸ¯ Basic purpose from README<br/>ğŸ“Š Lower confidence"]
    
    AISuccess --> CacheResult["ğŸ’¾ Cache Capsule<br/>ğŸ’¾ Write to cache/capsule_*.json<br/>ğŸ§  Load to memory<br/>ğŸ“‡ Build search index"]
    
    AIFallback --> CacheResult
    LocalOnly --> CacheResult
    
    CacheResult --> Ready["âœ… Ready for Queries"]

    classDef start fill:#e3f2fd,stroke:#2196f3,stroke-width:3px,color:#000
    classDef decision fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef local fill:#f5f5f5,stroke:#9e9e9e,stroke-width:2px,color:#000
    classDef ai fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000
    classDef cache fill:#f1f8e9,stroke:#795548,stroke-width:2px,color:#000
    classDef ready fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000

    class Start start
    class CheckDisabled,CheckGit,CheckAPI decision
    class LocalOnly,AIFallback local
    class NonGit,GitRepo,TryAI,AISuccess ai
    class CacheResult cache
    class Ready ready
```

### ğŸ“Š Git vs Non-Git: Detailed Behavior Matrix

| Aspect | **Non-Git Projects** | **Git Repositories** |
|--------|---------------------|----------------------|
| **ğŸ“ Metadata File** | âœ… Creates `.capsule.json` | âŒ No metadata file |
| **ğŸ¯ Purpose** | Guide indexing for loose files | Assume repo has own structure |
| **ğŸ“Š Resource Budgets** | `purpose.limits` (conservative) | `purpose.gitRepoOverrides` (generous) |
| **ğŸ“ Max Files** | 25 files | 50 files |
| **ğŸ’¾ Max Bytes** | 350KB | 800KB |
| **â±ï¸ Timeout** | 8 seconds | 12 seconds |
| **ğŸ§  AI Summarization** | âœ… Yes (if enabled) | âœ… Yes (if enabled) |
| **ğŸ”„ Refresh Trigger** | File changes + activity | File changes + activity |

### ğŸ”„ Capsule Refresh Mechanisms: When and How Often

```mermaid
flowchart TB
    subgraph Triggers ["âš¡ Refresh Triggers"]
        FileChange["ğŸ“ File Changes<br/>ğŸ” Chokidar detects edits<br/>â±ï¸ 750ms debounce<br/>ğŸ“‹ Enqueues app"]
        
        Activity["ğŸ“Š Activity Promotion<br/>ğŸ‘ï¸ Cursor IDE usage<br/>ğŸ“‚ Recent file access<br/>â±ï¸ Every 5 minutes<br/>ğŸ“‹ Promotes hot apps"]
        
        Startup["ğŸš€ Server Startup<br/>ğŸ’¾ Load existing capsules<br/>ğŸ“‹ Enqueue all apps<br/>ğŸ”„ Incremental updates"]
        
        Manual["ğŸ”§ Manual Bootstrap<br/>ğŸ› ï¸ workspace.bootstrap tool<br/>ğŸ”„ Force refresh<br/>âš¡ Immediate update"]
    end
    
    subgraph RateLimit ["ğŸš¦ Rate Limiting"]
        Queue["ğŸ“‹ Priority Queue<br/>ğŸ¥‡ Priority paths first<br/>ğŸ“Š 3 jobs/minute max<br/>âš¡ 3 concurrent max"]
        
        Debounce["â±ï¸ Debouncing<br/>ğŸ“ Per-app 750ms window<br/>ğŸ”„ Coalesces rapid changes<br/>ğŸ’¾ Prevents spam"]
    end
    
    subgraph Processing ["ğŸ­ Processing Pipeline"]
        Check["ğŸ” Check Cache<br/>ğŸ’¾ Load existing capsule<br/>ğŸ“… Check timestamps<br/>ğŸ”„ Decide if refresh needed"]
        
        Process["ğŸ§  Process App<br/>ğŸ¤– Try AI (if enabled)<br/>ğŸ  Fallback to local<br/>ğŸ’¾ Update cache"]
    end
    
    FileChange --> Debounce
    Activity --> Queue
    Startup --> Queue
    Manual --> Queue
    
    Debounce --> Queue
    Queue --> Check
    Check --> Process
    
    classDef trigger fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef rate fill:#e3f2fd,stroke:#2196f3,stroke-width:2px,color:#000
    classDef process fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px,color:#000

    class FileChange,Activity,Startup,Manual trigger
    class Queue,Debounce rate
    class Check,Process process
```

### ğŸ¯ Exact AI Service Usage Scenarios

#### âœ… **AI Services ARE Used When:**

1. **ğŸ§  Capsule Creation/Refresh** (Both Git and Non-Git):
   ```javascript
   // Code reference: processOne() function
   const ai = await aiSummarizeApp(job.appPath, limits);
   capsule = Object.assign({}, summarizeApp(job.appPath), {
     purpose: ai.purpose || 'Unknown',
     ai: { role: ai.role, confidence: ai.confidence, evidence_paths: ai.evidence_paths }
   });
   ```
   - **When**: App first discovered, file changes detected, manual refresh
   - **What AI does**: Analyzes representative files to extract purpose and classify role
   - **Fallback**: If AI fails, uses local heuristic (`summarizeApp()`)

2. **ğŸ”„ Activity-Based Promotions**:
   - **Frequency**: Every 5 minutes (if `activity.enable: true`)
   - **Trigger**: Apps with activity score â‰¥ `minScore` (default 3.0)
   - **Sources**: Cursor IDE state, session history, recent file modifications

#### âŒ **AI Services are NOT Used When:**

1. **ğŸš« Explicitly Disabled**:
   ```bash
   export WORKSPACE_MCP_AI=disabled
   # or
   export WORKSPACE_MCP_AI_DISABLE=1
   ```

2. **ğŸ” Query-Time Operations**:
   - **Search queries** (`workspace.search_semantic`) use pre-built capsules
   - **Tool calls** (`list_entrypoints`, `describe_symbol`) use cached data
   - **No real-time AI** during user interactions

3. **ğŸ’¾ Cache Hits**:
   - If capsule already exists and is recent, AI is skipped
   - Uses cached `purpose`, `role`, `confidence` from previous AI analysis

### â° Refresh Frequency by Scenario

| Scenario | Frequency | AI Usage | Cache Behavior |
|----------|-----------|----------|----------------|
| **ğŸ†• New App** | Immediate | âœ… AI analysis | ğŸ’¾ Create new capsule |
| **ğŸ“ File Changes** | 750ms debounced | âœ… AI re-analysis | ğŸ”„ Update existing capsule |
| **ğŸ“Š Activity Promotion** | Every 5 minutes | âœ… AI analysis | ğŸ”„ Refresh if stale |
| **ğŸ” Search Queries** | Every query | âŒ No AI | ğŸ“– Read cached capsule |
| **ğŸ› ï¸ Tool Calls** | Per call | âŒ No AI | ğŸ“– Read cached capsule |

### ğŸ”‘ What "AI Service Available" Means

When AI services are available and used:

```mermaid
flowchart LR
    subgraph Available ["âœ… AI Service Available"]
        API["ğŸ”‘ API Key Present<br/>(GOOGLE_API_KEY or OPENAI_API_KEY)"]
        --> Call["ğŸ“ API Call<br/>ğŸ“„ Send representative snippets<br/>ğŸ§  Get intelligent analysis"]
        --> Parse["ğŸ“ Parse Response<br/>ğŸ¯ Extract purpose<br/>ğŸ“Š Assign confidence<br/>ğŸ·ï¸ Classify role"]
        --> AIGenerated["ğŸŒŸ AI-Generated Capsule<br/>ğŸ¯ AI-generated purpose<br/>ğŸ“Š Confidence: 0.8-0.9<br/>ğŸ“„ Evidence paths"]
    end
    
    subgraph Unavailable ["âŒ AI Service Unavailable"]
        NoAPI["ğŸš« No API Key"]
        --> Heuristic["ğŸ  Local Heuristic<br/>ğŸ“ Parse README.md<br/>ğŸ“¦ Check package.json<br/>ğŸ“š Scan docs/ folder"]
        --> Basic["ğŸ“¦ Basic Capsule<br/>ğŸ¯ Heuristic purpose<br/>ğŸ“Š Confidence: 0.6<br/>ğŸ“„ File-based evidence"]
    end
    
    classDef available fill:#e8f5e8,stroke:#4caf50,stroke-width:2px,color:#000
    classDef unavailable fill:#fff3e0,stroke:#ff9800,stroke-width:2px,color:#000
    classDef aigenerated fill:#e8f5e8,stroke:#4caf50,stroke-width:3px,color:#000
    classDef basic fill:#f5f5f5,stroke:#9e9e9e,stroke-width:2px,color:#000

    class API,Call,Parse available
    class NoAPI,Heuristic unavailable
    class AIGenerated aigenerated
    class Basic basic
```

Code references:

```58:116:/Users/ashafi/Documents/work/tools/workspace-mcp/index.js
const DEFAULT_WORKSPACE_ROOT = '/Users/ashafi/Documents/work';
...
async function aiSummarizeApp(appPath, limits) {
  // Minimal stub: collect small representative snippets; call no external model yet.
  // In your environment, wire to MCP sampling client here.
}
```

```147:166:/Users/ashafi/Documents/work/tools/workspace-mcp/index.js
const inGit = isInsideGitRepo(job.appPath);
const limits = inGit ? PURPOSE_LIMITS.gitRepoOverrides : PURPOSE_LIMITS.limits;
if (!inGit) { await ensureMetadataFile(job.appPath); }
// Summarize â†’ write capsule cache â†’ update inâ€‘memory capsule
```

### Networking & Privacy

- External AI summarization is on by default. Disable via env (see below) if your policy requires fully local.
- If `WORKSPACE_MCP_AI_ENDPOINT` is set, it will POST representative snippets to that endpoint. Otherwise, if `OPENAI_API_KEY` is present, it will use OpenAI Chat Completions.
- If disabled or no provider is available, the system falls back to a local heuristic (no network calls).
- Telemetry is local (`cache/telemetry.log`).

### How to disable external AI

Set ONE of the following and restart:
```
export WORKSPACE_MCP_AI=disabled
# or
export WORKSPACE_MCP_AI_DISABLE=1
```

### How to configure external AI (default order: Gemini â†’ OpenAI â†’ local)

Option A: Gemini CLI (default priority)
```
export WORKSPACE_MCP_GEMINI_CLI=gemini           # or your wrapper
export WORKSPACE_MCP_GEMINI_MODEL=gemini-1.5-flash
export GOOGLE_API_KEY=your-gemini-api-key
# Optional custom args template (tokens: {MODEL}, {PROMPT})
# export WORKSPACE_MCP_GEMINI_ARGS="-m {MODEL} generate -p {PROMPT}"
```

Option B: OpenAI fallback
```
export OPENAI_API_KEY=sk-...
export WORKSPACE_MCP_AI_MODEL=gpt-4o-mini   # optional (default shown)
```

Option C: Generic HTTP endpoint (lowest priority)
```
export WORKSPACE_MCP_AI_ENDPOINT=https://your-ai-endpoint/summarize
export WORKSPACE_MCP_AI_AUTH="Bearer <TOKEN>"   # optional
```

---

## Operational Notes

- All file operations are constrained to `workspaceRoot`.
- Large files are summarized (head + signatures) to prevent heavy loads.
- Logs are not indexed by default.
- Activity promotion runs periodically when enabled.

---

## Example: End-to-End

1) Add the server in your MCP client (e.g., Cursor) with command:
```
node /path/to/workspace-mcp/index.js
```
2) Initialize config (first time):
```
npx workspace-mcp init
```
3) Start server:
```
npx workspace-mcp start
```
4) From your MCP client, call:
```
workspace.search_semantic("kubeVirt utils for Cypress")
```
â†’ The server reuses the capsule cache and Lunr index to return results quickly.


